/**
 * 课程 4.4: CUDA 静态全局变量详解
 * 文件名: global_memory.cu
 * 作者: 权 双
 * 日期: 2023-12-26
 * 功能: 静态全局变量使用演示
 *
 * 静态全局变量特点：
 * 1. 设备端声明 - 使用 __device__ 修饰符
 * 2. 全局可见 - 所有内核函数和设备函数都可访问
 * 3. 生命周期长 - 整个程序执行期间都存在
 * 4. 符号访问 - 通过符号名称在主机端访问
 * 5. 初始化灵活 - 可在声明时初始化或运行时设置
 *
 * 与动态全局内存的区别：
 * - 静态：编译时分配，符号访问，便于管理
 * - 动态：运行时分配，指针访问，更灵活但需手动管理
 */

#include <cuda_runtime.h>
#include <iostream>
#include "common.cuh"

/**
 * 静态全局变量声明
 *
 * __device__ 修饰符说明：
 * - 表示变量位于设备（GPU）端
 * - 全局作用域，所有内核和设备函数可访问
 * - 生命周期：整个程序执行期间
 * - 可在声明时初始化
 */
__device__ int d_x = 1;        // 初始化为 1 的全局变量
__device__ int d_y[2];         // 未初始化的全局数组（默认为 0）

/**
 * GPU 内核函数 - 演示静态全局变量的访问和修改
 *
 * 本内核展示了如何在 GPU 端直接访问和修改全局变量：
 * 1. 读取全局变量的值
 * 2. 修改全局数组的内容
 * 3. 输出计算结果
 */
__global__ void kernel(void)
{
    /**
     * 直接访问和修改静态全局变量
     *
     * 关键特点：
     * - 无需参数传递：全局变量对所有内核可见
     * - 直接访问：如同访问局部变量一样简单
     * - 自动同步：多个线程块访问同一全局变量时需要考虑同步
     */
    d_y[0] += d_x;  // d_y[0] = d_y[0] + d_x (初始: 10 + 1 = 11)
    d_y[1] += d_x;  // d_y[1] = d_y[1] + d_x (初始: 20 + 1 = 21)

    /**
     * 输出计算结果
     *
     * 注意：由于只启动了一个线程块和一个线程，
     * 不会出现多线程竞争问题
     */
    printf("d_x = %d, d_y[0] = %d, d_y[1] = %d.\n", d_x, d_y[0], d_y[1]);
}

/**
 * 主函数 - 演示静态全局变量的完整使用流程
 */
int main(int argc, char **argv)
{
    /**
     * 第一步：获取GPU设备信息
     */
    int devID = 0;
    cudaDeviceProp deviceProps;
    CUDA_CHECK(cudaGetDeviceProperties(&deviceProps, devID));
    std::cout << "运行GPU设备:" << deviceProps.name << std::endl;

    /**
     * 输出设备内存相关信息
     */
    std::cout << "全局内存大小: "
              << deviceProps.totalGlobalMem / (1024 * 1024) << " MB" << std::endl;
    std::cout << "共享内存每个块: "
              << deviceProps.sharedMemPerBlock / 1024 << " KB" << std::endl;

    /**
     * 第二步：从主机端设置静态全局变量的值
     *
     * cudaMemcpyToSymbol() 函数详解：
     * - 用途：将主机内存的数据复制到设备端的符号（全局变量）
     * - 参数1：设备端符号名称（变量名）
     * - 参数2：主机端数据源地址
     * - 参数3：复制的字节数
     * - 参数4：符号内的偏移量（可选，默认0）
     * - 参数5：复制方向（可选，默认HostToDevice）
     */
    int h_y[2] = {10, 20};  // 主机端的初始值

    std::cout << "\n设置初始值:" << std::endl;
    std::cout << "h_y[0] = " << h_y[0] << ", h_y[1] = " << h_y[1] << std::endl;

    // 将主机端的数组复制到设备端的全局变量
    CUDA_CHECK(cudaMemcpyToSymbol(d_y, h_y, sizeof(int) * 2));

    /**
     * 第三步：启动内核函数
     *
     * 配置说明：
     * - dim3 block(1): 每个线程块1个线程
     * - dim3 grid(1): 1个线程块
     * - 总线程数：1个线程
     *
     * 单线程设计原因：
     * - 避免多线程同时修改全局变量的竞争条件
     * - 简化示例，专注于全局变量的使用机制
     * - 在实际应用中，需要考虑原子操作或其他同步机制
     */
    dim3 block(1);
    dim3 grid(1);

    std::cout << "\n启动内核进行计算..." << std::endl;
    kernel<<<grid, block>>>();

    /**
     * 等待内核执行完成
     */
    CUDA_CHECK(cudaDeviceSynchronize());

    /**
     * 第四步：从设备端读取计算结果
     *
     * cudaMemcpyFromSymbol() 函数详解：
     * - 用途：将设备端符号（全局变量）的数据复制到主机内存
     * - 参数1：主机端目标地址
     * - 参数2：设备端符号名称（变量名）
     * - 参数3：复制的字节数
     * - 参数4：符号内的偏移量（可选，默认0）
     * - 参数5：复制方向（可选，默认DeviceToHost）
     */
    CUDA_CHECK(cudaMemcpyFromSymbol(h_y, d_y, sizeof(int) * 2));

    /**
     * 第五步：验证和显示结果
     */
    std::cout << "\n计算完成，结果验证:" << std::endl;
    printf("h_y[0] = %d, h_y[1] = %d.\n", h_y[0], h_y[1]);

    std::cout << "\n结果分析:" << std::endl;
    std::cout << "d_y[0]: 10 + 1 = " << h_y[0] << std::endl;
    std::cout << "d_y[1]: 20 + 1 = " << h_y[1] << std::endl;

    /**
     * 第六步：清理资源
     */
    CUDA_CHECK(cudaDeviceReset());

    return 0;
}

/**
 * 学习要点总结：
 *
 * 1. 静态全局变量的声明和使用：
 *    - 使用 __device__ 修饰符
 *    - 可在声明时初始化
 *    - 全局作用域，所有内核可访问
 *    - 生命周期覆盖整个程序执行期间
 *
 * 2. 主机端与设备端的数据交换：
 *    - cudaMemcpyToSymbol(): 主机 -> 设备符号
 *    - cudaMemcpyFromSymbol(): 设备符号 -> 主机
 *    - 通过符号名称而非指针访问
 *    - 类型安全的数据传输
 *
 * 3. 使用场景：
 *    - 全局配置参数
 *    - 跨内核共享的数据
 *    - 简单的全局状态管理
 *    - 避免参数传递的开销
 *
 * 4. 与其他内存类型的对比：
 *    静态全局变量：
 *    - 优点：易于使用，符号访问，类型安全
 *    - 缺点：大小固定，编译时确定
 *
 *    动态全局内存：
 *    - 优点：运行时分配，大小灵活
 *    - 缺点：需要手动管理，指针访问
 *
 *    常量内存：
 *    - 优点：缓存加速，广播高效
 *    - 缺点：只读，大小限制
 *
 *    共享内存：
 *    - 优点：速度最快，线程块内共享
 *    - 缺点：生命周期短，容量小
 *
 * 5. 多线程访问注意事项：
 *    - 竞争条件：多个线程同时修改可能导致不确定结果
 *    - 原子操作：使用atomicAdd()等原子函数
 *    - 同步机制：适当使用__syncthreads()或其他同步原语
 *    - 读写分离：尽可能设计为只读或写时复制模式
 *
 * 6. 性能考虑：
 *    - 访问速度：与普通全局内存相同
 *    - 缓存友好：可能被L1/L2缓存加速
 *    - 内存占用：占用全局内存空间
 *    - 传输开销：符号传输比指针传输略有开销
 *
 * 7. 实际应用示例：
 *    - 数学常数（PI、E等）
 *    - 算法参数（学习率、阈值等）
 *    - 全局计数器（需原子操作）
 *    - 状态标志（错误代码、完成标志等）
 *
 * 8. 程序输出解释：
 *    - GPU输出: "d_x = 1, d_y[0] = 11, d_y[1] = 21"
 *    - 主机输出: "h_y[0] = 11, h_y[1] = 21"
 *    - 证明了设备端计算和主机端读取的一致性
 */